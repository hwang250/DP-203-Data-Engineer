{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z40SJW9I9Rh9"
      },
      "source": [
        "# Knowledge Distillation\n",
        "Created in PyTorch by [Laia Tarrés](https://www.linkedin.com/in/laia-tarres-9a5369138) for the [Postgraduate Course in Artificial Intelligence with Deep Learning](https://www.talent.upc.edu/ing/estudis/formacio/curs/310400/postgrau-artificial-intelligence-deep-learning/) ([UPC School](https://www.talent.upc.edu/ing/), 2021).\n",
        "\n",
        "Updated by [Gerard I. Gállego](https://www.linkedin.com/in/gerard-gallego/).\n",
        "\n",
        "*Based on other notebooks that use distillation [1](https://colab.research.google.com/github/sayakpaul/Knowledge-Distillation-in-Keras/blob/master/Distillation_with_Transfer_Learning.ipynb#scrollTo=b1jE623hh781), [2](https://colab.research.google.com/github/keras-team/keras-io/blob/master/examples/vision/ipynb/knowledge_distillation.ipynb), [3](https://colab.research.google.com/drive/1-yHSQTljXyca2aSFhpM2y4n9B4M-KWso#scrollTo=3JApQdNz19bT), [4](https://koushik-nov01.medium.com/knowledge-distillation-with-pytorch-40febcf77440) for educational purposes.*\n",
        "\n",
        "Modern state-of-the-art neural network architectures are HUGE.\n",
        "\n",
        "Unfortunately, more is sometimes not better when it comes to the number of parameters. Sure, more parameters seem to mean better results, but also massive computational costs.\n",
        "\n",
        "However, deploying much smaller models can also present a significant challenge for machine learning engineers. In practice, small and fast models are much better than massive ones.\n",
        "\n",
        "Because of this, researchers and engineers have put significant energy into compressing models.\n",
        "\n",
        "To optimize these costs by compressing the models, three main methods have emerged:\n",
        "\n",
        "*   Weight pruning\n",
        "*   Quantization\n",
        "*   knowledge distillation\n",
        "\n",
        "\n",
        "Today we will focus on Knowledge Distillation. Knowledge Distillation is a procedure for model compression, in which a small (student) model is trained to match a large pre-trained (teacher) model.\n",
        "\n",
        "Knowledge is transferred from the teacher model to the student by minimizing a loss function, aimed at matching the teacher outputs as well as ground-truth labels.\n",
        "\n",
        "**Reference:**\n",
        "\n",
        "- [Hinton et al. (2015)](https://arxiv.org/abs/1503.02531)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NC8B-UAzFTVG"
      },
      "source": [
        "#Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEH667VNX_Sa",
        "outputId": "36802c38-fadc-4429-8b9f-0be7a34b7c6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torchinfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "tJlH25EvX_Sb"
      },
      "outputs": [],
      "source": [
        "# Necessary imports\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchinfo import summary\n",
        "from tqdm import tqdm\n",
        "from timeit import default_timer as timer\n",
        "\n",
        "# For reproducibility\n",
        "torch.manual_seed(0)\n",
        "torch.backends.cudnn.benchmark = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o63CO4z5Fr67"
      },
      "source": [
        "Define hyerparameters, and remember to set the runtime type accelerator as GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "5C3s8wASX_Sb"
      },
      "outputs": [],
      "source": [
        "hparams = {\n",
        "    'batch_size':32,\n",
        "    'num_epochs':3,\n",
        "    'num_classes':10,\n",
        "    'learning_rate':1e-4,\n",
        "    'learning_rate_dist': 5e-3,\n",
        "    'log_interval':2000,\n",
        "}\n",
        "hparams['device'] = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "assert(hparams['device']=='cuda')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGllOagRFYAn"
      },
      "source": [
        "# Define MNIST dataset and dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mELWPxwLX_Sb",
        "outputId": "56aa91bd-fe62-470a-9690-91640efdbf53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 57.8MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 1.69MB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 14.9MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 6.35MB/s]\n"
          ]
        }
      ],
      "source": [
        "train_dataset = torchvision.datasets.MNIST(\n",
        "    root=\"dataset/\",\n",
        "    train=True,\n",
        "    transform=transforms.ToTensor(),\n",
        "    download=True\n",
        ")\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(\n",
        "    root=\"dataset/\",\n",
        "    train=False,\n",
        "    transform=transforms.ToTensor(),\n",
        "    download=True\n",
        ")\n",
        "# Create train and test dataloaders\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=hparams['batch_size'], shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=hparams['batch_size'], shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WKDBeUOGBit"
      },
      "source": [
        "# Define the Teacher Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "JhUhwIFdX_Sc"
      },
      "outputs": [],
      "source": [
        "class TeacherModel(nn.Module):\n",
        "    def __init__(self, in_channels=1, num_classes=10):\n",
        "        super(TeacherModel, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_channels=in_channels,\n",
        "            out_channels=64,\n",
        "            kernel_size=3,\n",
        "            stride=1,\n",
        "            padding=1,\n",
        "        )\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv2 = nn.Conv2d(\n",
        "            in_channels=64,\n",
        "            out_channels=256,\n",
        "            kernel_size=3,\n",
        "            stride=1,\n",
        "            padding=1,\n",
        "        )\n",
        "        self.fc1 = nn.Linear(256 * 7 * 7, hparams['num_classes'])\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.pool(x)\n",
        "        x = x.reshape(x.shape[0], -1)\n",
        "        x = self.fc1(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hxjn97tGPrY"
      },
      "source": [
        "## Exercise 1: Declare the teacher model, and list the number of parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ED8NqiSX_Sc",
        "outputId": "eaed3a0d-65f6-4871-f49a-af44181b9d15"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "TeacherModel                             [1, 10]                   --\n",
              "├─Conv2d: 1-1                            [1, 64, 28, 28]           640\n",
              "├─MaxPool2d: 1-2                         [1, 64, 14, 14]           --\n",
              "├─Conv2d: 1-3                            [1, 256, 14, 14]          147,712\n",
              "├─MaxPool2d: 1-4                         [1, 256, 7, 7]            --\n",
              "├─Linear: 1-5                            [1, 10]                   125,450\n",
              "==========================================================================================\n",
              "Total params: 273,802\n",
              "Trainable params: 273,802\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (Units.MEGABYTES): 29.58\n",
              "==========================================================================================\n",
              "Input size (MB): 0.00\n",
              "Forward/backward pass size (MB): 0.80\n",
              "Params size (MB): 1.10\n",
              "Estimated Total Size (MB): 1.90\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# # TODO: Declare the teacher model\n",
        "# teacher_model = ...\n",
        "# # TODO: List its parameters, given an input of [bs, nchannels, width, depth], using the summary function from torchinfo\n",
        "# summary(...)\n",
        "\n",
        "# Declare the teacher model\n",
        "teacher_model = TeacherModel(in_channels=1, num_classes=hparams['num_classes'])\n",
        "\n",
        "# List its parameters using torchinfo.summary\n",
        "# Input size: (batch_size, channels, height, width)\n",
        "summary(teacher_model, input_size=(1, 1, 28, 28))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "heORRbM6HNs5"
      },
      "source": [
        "# Define the student model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "r22auZ7cX_Sc"
      },
      "outputs": [],
      "source": [
        "class StudentModel(nn.Module):\n",
        "    def __init__(self, in_channels=1, num_classes=10):\n",
        "        super(StudentModel, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_channels=in_channels,\n",
        "            out_channels=8,\n",
        "            kernel_size=3,\n",
        "            stride=1,\n",
        "            padding=1,\n",
        "        )\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv2 = nn.Conv2d(\n",
        "            in_channels=8,\n",
        "            out_channels=16,\n",
        "            kernel_size=3,\n",
        "            stride=1,\n",
        "            padding=1,\n",
        "        )\n",
        "        self.fc1 = nn.Linear(16 * 7 * 7, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.pool(x)\n",
        "        x = x.reshape(x.shape[0], -1)\n",
        "        x = self.fc1(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrxgujRVJ1lo"
      },
      "source": [
        "## Exercise 2: Declare the student model, and list the number of parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jgQSkrCX_Sd",
        "outputId": "f305f8cf-f109-4707-868f-dd6da4aff47c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "StudentModel                             [1, 10]                   --\n",
              "├─Conv2d: 1-1                            [1, 8, 28, 28]            80\n",
              "├─MaxPool2d: 1-2                         [1, 8, 14, 14]            --\n",
              "├─Conv2d: 1-3                            [1, 16, 14, 14]           1,168\n",
              "├─MaxPool2d: 1-4                         [1, 16, 7, 7]             --\n",
              "├─Linear: 1-5                            [1, 10]                   7,850\n",
              "==========================================================================================\n",
              "Total params: 9,098\n",
              "Trainable params: 9,098\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (Units.MEGABYTES): 0.30\n",
              "==========================================================================================\n",
              "Input size (MB): 0.00\n",
              "Forward/backward pass size (MB): 0.08\n",
              "Params size (MB): 0.04\n",
              "Estimated Total Size (MB): 0.11\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Declare the student model\n",
        "student_model = StudentModel(in_channels=1, num_classes=10)\n",
        "\n",
        "# Show the model summary\n",
        "summary(student_model, input_size=(1, 1, 28, 28))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_09kqJbqHcWG"
      },
      "source": [
        "Let's define a helper function that computes the accuracy and the number of correct predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "0CceSZkTX_Sd"
      },
      "outputs": [],
      "source": [
        "def check_accuracy(loader, model, device):\n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "\n",
        "            scores = model(x)\n",
        "            _, predictions = scores.max(1)\n",
        "            num_correct += (predictions == y).sum()\n",
        "            num_samples += predictions.size(0)\n",
        "\n",
        "\n",
        "    model.train()\n",
        "    return (num_correct/num_samples).item()\n",
        "\n",
        "def correct_predictions(predicted_batch, label_batch):\n",
        "  pred = predicted_batch.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
        "  acum = pred.eq(label_batch.view_as(pred)).sum().item()\n",
        "  return acum"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ma_kQc6mHksV"
      },
      "source": [
        "Let's define a basic training pipeline for any network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkvhC8UqKH7g"
      },
      "source": [
        "#Exercise 3: define the basic training pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Piox05qfX_Sd"
      },
      "outputs": [],
      "source": [
        "def train_model(model, criterion, optimizer, train_loader, epochs):\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        losses = []\n",
        "        device = hparams['device']\n",
        "        model.to(device)\n",
        "\n",
        "        pbar = tqdm(train_loader, total=len(train_loader), position=0, leave=True, desc=f\"Epoch {epoch}\")\n",
        "        for data, targets in pbar:\n",
        "            data = data.to(device)\n",
        "            targets = targets.to(device)\n",
        "\n",
        "            # # TODO: forward method\n",
        "            # scores = ...\n",
        "            # loss = ...\n",
        "\n",
        "            # losses.append(loss.item())\n",
        "\n",
        "            # # TODO: backward pass\n",
        "            # loss...\n",
        "            # optimizer...\n",
        "            # optimizer...\n",
        "            # ✅ Forward pass\n",
        "            scores = model(data)\n",
        "            loss = criterion(scores, targets)\n",
        "\n",
        "            losses.append(loss.item())\n",
        "\n",
        "            # ✅ Backward pass\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        avg_loss = sum(losses) / len(losses)\n",
        "        acc = check_accuracy(test_loader, model, device)\n",
        "        print(f\"Loss:{avg_loss:.2f}\\tAccuracy:{acc:.2f}\")\n",
        "\n",
        "    return model\n",
        "\n",
        "def test_model(model, test_loader):\n",
        "  model.eval()\n",
        "  device = hparams['device']\n",
        "  eval_loss = 0\n",
        "  acc = 0\n",
        "  logsoftmax = nn.LogSoftmax(dim=-1)\n",
        "  beg_t = timer()\n",
        "  with torch.no_grad():\n",
        "      for data, target in test_loader:\n",
        "          data, target = data.to(device), target.to(device)\n",
        "          output = logsoftmax(model(data))\n",
        "          # compute number of correct predictions in the batch\n",
        "          acc += correct_predictions(output, target)\n",
        "  # Average acc across all correct predictions batches now\n",
        "  end_t = timer()\n",
        "  train_time = end_t - beg_t\n",
        "  test_acc = 100. * acc / len(test_loader.dataset)\n",
        "  print('Test set:  Accuracy: {}/{} ({:.0f}%) Time to test: {} seconds.'.format(\n",
        "       acc, len(test_loader.dataset), test_acc, round(train_time, 2),\n",
        "      ))\n",
        "  return test_acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlVyZ4voPKXz"
      },
      "source": [
        "##Train the teacher model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yg0GzPtrX_Sd",
        "outputId": "cc77af8a-0a57-4e18-f360-4d93d264d951"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0: 100%|██████████| 1875/1875 [00:11<00:00, 158.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss:0.12\tAccuracy:0.99\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 1875/1875 [00:11<00:00, 163.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss:0.04\tAccuracy:0.99\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 1875/1875 [00:10<00:00, 174.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss:0.03\tAccuracy:0.99\n",
            "Test set:  Accuracy: 9905/10000 (99%) Time to test: 1.66 seconds.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "99.05"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# TODO: Declare the teacher model, criterion and optimizer\n",
        "# teacher_model = ...\n",
        "# criterion = nn...\n",
        "# optimizer = torch.optim.Adam(..., ...)\n",
        "\n",
        "# TODO: Declare the teacher model, criterion and optimizer\n",
        "teacher_model = TeacherModel(in_channels=1, num_classes=hparams['num_classes'])\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "#optimizer = torch.optim.Adam(teacher_model.parameters(), lr=hparams['lr'])\n",
        "optimizer = torch.optim.Adam(teacher_model.parameters(), lr=1e-3)\n",
        "teacher_model = train_model(teacher_model, criterion, optimizer, train_loader, epochs=hparams['num_epochs'])\n",
        "test_model(teacher_model, test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIClVGA_JkfI"
      },
      "source": [
        "# Exercise 4: Perform knowledge distillation (transfer knowledge from the teacher to the student)\n",
        "\n",
        "In this example, we have two losses that are combined to obtain the loss that will be backpropagated in order to train the student.\n",
        "\n",
        "We have:\n",
        "\n",
        "\n",
        "*   **Classification loss (student loss)**: the typical loss: in this case, the network is outputing right before the softmax. We apply CrossEntropyLoss.\n",
        "*   **Distillation loss**: in this loss, we are comparing the softened outputs from the softmax. As the model is outputing right before the softmax, we will have to apply the softmax with the corresponding temperature term and then MSELoss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "JXaipIiQX_Se"
      },
      "outputs": [],
      "source": [
        "def train_step(teacher, student, optimizer, classification_loss_fn, distillation_loss_fn, temp, alpha, epoch, device):\n",
        "    losses = []\n",
        "    pbar = tqdm(train_loader, total=len(train_loader), position=0, leave=True, desc=f\"Epoch {epoch}\")\n",
        "    device = hparams['device']\n",
        "\n",
        "    for data, targets in pbar:\n",
        "        # Get data to cuda if possible\n",
        "        data = data.to(device)\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        # with torch.no_grad():\n",
        "        #     # TODO: Compute teacher soft predictions\n",
        "        #     teacher_preds = ...\n",
        "\n",
        "        # # TODO: Get the student soft targets and compute the classification loss between\n",
        "        # student_preds = ...\n",
        "\n",
        "        # # TODO: compute the classification loss\n",
        "        # student_loss = ...\n",
        "        # # TODO: Compute the distillation loss. Remember, that we are comparing the outputs of the softmax for both predictions\n",
        "        # distillation_loss = ...( F.softmax(... / temp, dim=1), F.softmax(.../ temp, dim=1) )\n",
        "\n",
        "        # loss = alpha * student_loss + (1 - alpha) * distillation_loss\n",
        "        # losses.append(loss.item())\n",
        "\n",
        "        # # TODO: backward pass and update optimizer.\n",
        "        # loss...\n",
        "        # optimizer...\n",
        "        # optimizer...\n",
        "        with torch.no_grad():\n",
        "            # ✅ Teacher soft predictions (logits)\n",
        "            teacher_preds = teacher(data)\n",
        "\n",
        "        # ✅ Student predictions (logits)\n",
        "        student_preds = student(data)\n",
        "\n",
        "        # ✅ Classification loss (between student logits and labels)\n",
        "        student_loss = classification_loss_fn(student_preds, targets)\n",
        "\n",
        "        # ✅ Distillation loss (between softened softmax outputs)\n",
        "        distillation_loss = distillation_loss_fn(\n",
        "            F.softmax(student_preds / temp, dim=1),\n",
        "            F.softmax(teacher_preds / temp, dim=1)\n",
        "        )\n",
        "\n",
        "        # ✅ Combine losses\n",
        "        loss = alpha * student_loss + (1 - alpha) * distillation_loss\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        # ✅ Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    avg_loss = sum(losses) / len(losses)\n",
        "    return avg_loss\n",
        "\n",
        "def train_distillation(teacher, student, optimizer, classification_loss_fn, distillation_loss_fn, epochs, temp=7, alpha=0.3, device='cuda'):\n",
        "    device = hparams['device']\n",
        "    teacher = teacher.to(device)\n",
        "    student = student.to(device)\n",
        "    teacher.eval()\n",
        "    student.train()\n",
        "    for epoch in range(epochs):\n",
        "        loss = train_step(\n",
        "            teacher,\n",
        "            student,\n",
        "            optimizer,\n",
        "            classification_loss_fn,\n",
        "            distillation_loss_fn,\n",
        "            temp,\n",
        "            alpha,\n",
        "            epoch,\n",
        "            device\n",
        "        )\n",
        "        acc = check_accuracy(test_loader, student, device)\n",
        "        print(f\"Loss:{loss:.2f}\\tAccuracy:{acc:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGFKy-4kT-ZV"
      },
      "source": [
        "Let's check what temperature scaling is doing, and how it is \"flattening\" the outputs of the softmax."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xL4p0l_iX_Se",
        "outputId": "bd8f4f96-f84b-4348-a2e3-6d9a7029e9a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logits: [ 1.  2.  3. -1.]\n",
            "Logits exp: [ 2.71828183  7.3890561  20.08553692  0.36787944]\n",
            "Logits exp normalized: [0.08894682 0.24178252 0.65723302 0.01203764]\n",
            "Temperature[1.0] - [0.08894682 0.24178252 0.65723302 0.01203764]\n",
            "Temperature[5.0] - [0.22812574 0.2786334  0.34032361 0.15291725]\n",
            "Temperature[7.0] - [0.23608545 0.27233991 0.31416179 0.17741285]\n",
            "Temperature[10.0] - [0.24123681 0.2666079  0.2946473  0.19750799]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "logits=np.array([1.,2.,3.,-1.])\n",
        "print(f'Logits: {logits}')\n",
        "logits_exp = np.exp(logits)\n",
        "print(f'Logits exp: {logits_exp}')\n",
        "logits_exp_normalized = np.exp(logits)/sum(np.exp(logits)) #this would be like applying the softmax\n",
        "print(f'Logits exp normalized: {logits_exp_normalized}')\n",
        "\n",
        "#Let's try with a few values of T:\n",
        "T = [1.,5.,7.,10.]\n",
        "\n",
        "for t in T:\n",
        "  logits_exp_normalized_t = np.exp(logits/t)/sum(np.exp(logits/t))\n",
        "  print(f'Temperature[{t}] - {logits_exp_normalized_t}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCa3rGmWV1Z3"
      },
      "source": [
        "##Exercise 5: call the distillation function\n",
        "\n",
        "You should declare the two types of losses:\n",
        "\n",
        "\n",
        "1.   The appropiate for classification, when the model doesn't have a last activation layer. Categorical Cross entropy is recommended.\n",
        "2.   The appropiate for distillation, which will be able to compare between softened outputs of the softmax. MSE is recommended"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EFWgeZNIX_Se",
        "outputId": "7afd11ef-30d9-4061-b869-3663c7eb10b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0: 100%|██████████| 1875/1875 [00:13<00:00, 142.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss:0.06\tAccuracy:0.97\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 1875/1875 [00:11<00:00, 157.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss:0.02\tAccuracy:0.98\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 1875/1875 [00:14<00:00, 130.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss:0.01\tAccuracy:0.99\n",
            "Test set:  Accuracy: 9853/10000 (99%) Time to test: 1.17 seconds.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "98.53"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "# TODO: declare what you need to call the train_distillation function\n",
        "#\n",
        "# Declare the student model\n",
        "student_model = StudentModel(in_channels=1, num_classes=hparams['num_classes'])\n",
        "\n",
        "# Declare the two types of losses\n",
        "classification_loss_fn = nn.CrossEntropyLoss()\n",
        "distillation_loss_fn = nn.MSELoss()\n",
        "\n",
        "# Declare the optimizer\n",
        "optimizer = torch.optim.Adam(student_model.parameters(), lr=1e-3)\n",
        "train_distillation(teacher_model, student_model, optimizer, classification_loss_fn, distillation_loss_fn, epochs=hparams['num_epochs'], temp=6, alpha=0.2, device = hparams['device'])\n",
        "test_model(student_model, test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmTiMgfFI2wb"
      },
      "source": [
        "##Exercise 6: For comparison, let's train the student model from scratch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6BXeKtsEX_Se",
        "outputId": "dec8afa1-912a-4843-fc03-5f0466276410"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0: 100%|██████████| 1875/1875 [00:10<00:00, 183.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss:0.25\tAccuracy:0.97\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 1875/1875 [00:10<00:00, 183.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss:0.08\tAccuracy:0.98\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 1875/1875 [00:12<00:00, 150.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss:0.06\tAccuracy:0.98\n",
            "Test set:  Accuracy: 9819/10000 (98%) Time to test: 1.13 seconds.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "98.19"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "# TODO: declare a new student model\n",
        "# student_model= ....to(hparams['device'])\n",
        "# criterion = nn...\n",
        "# optimizer = torch.optim.Adam(..., ...)\n",
        "# Declare a new student model (no knowledge distillation)\n",
        "student_model = StudentModel(in_channels=1, num_classes=10).to(hparams['device'])\n",
        "\n",
        "# Classification loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Optimizer\n",
        "optimizer = torch.optim.Adam(student_model.parameters(), lr=1e-3)\n",
        "student_model = train_model(student_model, criterion, optimizer, train_loader, hparams['num_epochs'])\n",
        "test_model(student_model, test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55Bo0ixWUWAn"
      },
      "source": [
        "# Conclusions\n",
        "\n",
        "Yay! You have seen a didactic method of how to implement distillation. Although you probably haven't seen huge improvements in terms of accuracy, check how faster the student model is from the teacher when doing inference (test). And imagine how big of an impact that has when we are working with huge networks and with way bigger datasets than MNIST.\n",
        "\n",
        "There are many uses for Distillation, but one of the most impactful have been DistilBERT, a distilled version of the famous BERT transformer.\n",
        "\n",
        "#Extra:\n",
        "\n",
        "Do some further experiments with distillation, which combination gives you better results when varying different values for:\n",
        "\n",
        "*   temp\n",
        "*   alpha\n",
        "*   loss for distillation (note that we are using mse to compare the outputs of the softmax scaled, but we could also use divergence_loss_fn to compare the outputs of the log_softmax, among other loss functions)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6eDroO4MX_Sf",
        "outputId": "52c7ee08-4d35-4252-c4b1-1434e41654cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0: 100%|██████████| 1875/1875 [00:12<00:00, 152.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss:0.06\tAccuracy:0.97\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 1875/1875 [00:11<00:00, 159.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss:0.02\tAccuracy:0.98\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 1875/1875 [00:11<00:00, 159.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss:0.02\tAccuracy:0.98\n",
            "Test set:  Accuracy: 9819/10000 (98%) Time to test: 1.51 seconds.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "98.19"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "# # TODO: declare what you need to call the train_distillation function\n",
        "# student_model = ...\n",
        "# student_loss_fn = ...\n",
        "# mse_loss_fn = ...\n",
        "# #divergence_loss_fn = nn.KLDivLoss(reduction=\"batchmean\", log_target=True)\n",
        "# optimizer = ...\n",
        "# Experiment: declare student and losses\n",
        "student_model = StudentModel(in_channels=1, num_classes=hparams['num_classes']).to(hparams['device'])\n",
        "\n",
        "# Classification loss (typical for labels)\n",
        "student_loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# Distillation loss — choose one:\n",
        "mse_loss_fn = nn.MSELoss()\n",
        "# or for log-softmax outputs:\n",
        "kl_div_loss_fn = nn.KLDivLoss(reduction='batchmean', log_target=True)\n",
        "\n",
        "# Optimizer\n",
        "optimizer = torch.optim.Adam(student_model.parameters(), lr=1e-3)\n",
        "#train_distillation(teacher_model, student_model, optimizer, student_loss_fn, mse_loss_fn, epochs=hparams['num_epochs'], temp=..., alpha=..., device = hparams['device'])\n",
        "\n",
        "train_distillation(\n",
        "    teacher_model,\n",
        "    student_model,\n",
        "    optimizer,\n",
        "    student_loss_fn,\n",
        "    mse_loss_fn,\n",
        "    epochs=hparams['num_epochs'],\n",
        "    temp=6,       # 2, 4, 6, 8 등 시도 가능\n",
        "    alpha=0.2,    # 0.1~0.7 정도 시도해보세요\n",
        "    device=hparams['device']\n",
        ")\n",
        "\n",
        "\n",
        "test_model(student_model, test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqxlA5mmFqMi"
      },
      "source": [
        "# Some cool Examples where they use distillation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CX7MPQcRQzYI"
      },
      "source": [
        "## DistilBert\n",
        "In the following example, you can experiment with one of the most famous aplications of distillation: DistilBERT. In this [paper](https://arxiv.org/abs/1910.01108) they proved that they could use a smaller version of the model with fewer parameters and less computational resources.\n",
        "\n",
        "For comparison:\n",
        "\n",
        "BERT had 110 million parameters, and has 668 inference time.\n",
        "DistilBERT had 60 million parameters and has 410s inference time.\n",
        "\n",
        "That is, reducing 40% the number of parameters and the network being faster without losing performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "qQXxn_VOX_Sf"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "!pip install -q transformers datasets\n",
        "\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoModel, AutoTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269,
          "referenced_widgets": [
            "c81a5afb570c4284a1381ad5344acd90",
            "f166517755ea484ca5e086a2f4cd9d66",
            "937fbc53036c40f6be22de5651d57f27",
            "0e2e9a5dfccc495e91bde30a60ebfc29",
            "8ed445b9216f4e0396688b5cefafad57",
            "8a7b7ff0696c464fa7ab3c70de3f5cf2",
            "61bb54da25834f8689263d2eb2dac209",
            "7d3b5874ab3442c89581d3748a3fd519",
            "ba22c6239bc8414f9ec7ce6a11feabb5",
            "1e5327ac14e348b68c471f0760364721",
            "a585ed086a434fb4862503a439de621a",
            "720dd3eab2f44227a27a08d07da33ba3",
            "1858d473b2294167b0ba7a1d356412a3",
            "a8335150883a435ebdaff8f83747d7c8",
            "7da9ba9584eb4c199a1ca7affcaa87a7",
            "37455358499946e593450c4a174a960d",
            "f79f52d83b1843cfb0539a598855f6eb",
            "b9c3662290154070804e54a31f6f9723",
            "ba0c3563208b492399023b479aeba403",
            "bb7d925e08814c6693893ec725c1d8c6",
            "3968ae5468a54297a99309b7b3a9697b",
            "ca3cc2978efe4fffb237bda37c661acd",
            "1bf5445c79bc45abb382deb8019c059d",
            "b8de44a84107417e95e4bbcb9bf99429",
            "5d3db767184a4d20bd23a5254b751a8c",
            "5b0bf6a6dac54e17bbda7ed95a0f8d2c",
            "75eb947d793a47c3a3a8ebad3fa58c7c",
            "cdc8f3bdc09545d9a840788a66e11837",
            "0351027492f64dbbab0bff6d8a820d90",
            "62c9457f615b4a3595059116b562da5a",
            "5041d38bf5fe4ca3b8c336b6ba1b7fa6",
            "5abe22d7130c4a48919cd5bece17050e",
            "1af0182c7bee44b9a4799a31983fcda4",
            "2655ff2608bc448b826ba3a4a8d8be0d",
            "ebd4ae7240114df4acb0f6afd53fc512",
            "371043f28b6148a097a24e4be16f222e",
            "f5e8c674fad744c8ae0daeeebbc856bd",
            "50668129d2fa4edaa3954fc2155b38b3",
            "ce0a556a0f8c4ab1adb7de356872dcb6",
            "981de31d3d184e7b976efaebf2ec122c",
            "b3ec5847eae14a50bdfb2732d3dd64c9",
            "f0820a0496384b1b9bdb0830bd038c4d",
            "61cc53055c834087b12bb3fd939793bb",
            "75d216c1015a402eb79ddcc51fcfa66c"
          ]
        },
        "id": "i24c0IyQX_Sf",
        "outputId": "df1b48fa-5705-414b-94ac-3977726f3d34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c81a5afb570c4284a1381ad5344acd90"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "720dd3eab2f44227a27a08d07da33ba3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1bf5445c79bc45abb382deb8019c059d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2655ff2608bc448b826ba3a4a8d8be0d"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "distilbert_tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "distilbert = AutoModel.from_pretrained(\"distilbert-base-uncased\")\n",
        "\n",
        "def get_sents_representations(sents):\n",
        "    encoded_input = distilbert_tokenizer(sents, return_tensors='pt', padding=True, truncation=True)\n",
        "\n",
        "    distilbert_output = distilbert(**encoded_input)[0]\n",
        "    sentence_repr = distilbert_output[:, 0]\n",
        "\n",
        "    return distilbert_output, sentence_repr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m2PskOpTX_Sf"
      },
      "outputs": [],
      "source": [
        "#@title  { run: \"auto\", vertical-output: true }\n",
        "\n",
        "#@markdown Show 5 DistilBERT sentence representations to 2-D\n",
        "sentence_1 = \"Hello, my name is Joe\" #@param {type:\"string\"}\n",
        "sentence_2 = \"Hi, I'm Joey\" #@param {type:\"string\"}\n",
        "sentence_3 = \"Goodbye, see you at 5pm\" #@param {type:\"string\"}\n",
        "sentence_4 = \"Bye, see you later\" #@param {type:\"string\"}\n",
        "sentence_5 = \"Attention is All You Need\" #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "sentences = [sentence_1, sentence_2, sentence_3, sentence_4, sentence_5]\n",
        "\n",
        "distilbert_output, sentence_repr = get_sents_representations(sentences)\n",
        "\n",
        "print(f\"DistilBERT output: {distilbert_output.shape}\")\n",
        "print(f\"Sentence representations: {sentence_repr.shape}\")\n",
        "print(\"\\n\")\n",
        "\n",
        "pca = PCA(n_components=2)\n",
        "sentence_repr_2d = pca.fit_transform(sentence_repr.detach().numpy())\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "plt.scatter(sentence_repr_2d[:,0], sentence_repr_2d[:,1])\n",
        "plt.title(\"Sentence representations (PCA projection)\")\n",
        "plt.xlim(sentence_repr_2d[:,0].min() - 1, sentence_repr_2d[:,0].max() + 4)\n",
        "plt.ylim(sentence_repr_2d[:,1].min() - 1, sentence_repr_2d[:,1].max() + 1)\n",
        "\n",
        "for x, y, s in zip(sentence_repr_2d[:,0], sentence_repr_2d[:,1], sentences):\n",
        "    plt.text(x+0.15, y+0.15, s)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRP1fWn2RpwQ"
      },
      "source": [
        "## TinyGAN\n",
        "In the following example, you can experiment with a computer-vision related application: GANS.\n",
        "\n",
        "one of the most famous aplications of distillation: DistilBERT. In this [paper](https://arxiv.org/abs/1910.01108) they proved that they could use a smaller version of the model with fewer parameters and less computational resources.\n",
        "\n",
        "For comparison:\n",
        "\n",
        "*   BigGAN had 50.1 million parameters for the Generator, that performed 8.32 flops.\n",
        "*   TinyGAN had 3.1 million parameters for the Generator, that performed 0.44 flops.\n",
        "\n",
        "\n",
        "That is, using a model that is 16 times smaller without loosing performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z6acAmxcX_Sg"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/terarachang/ACCV_TinyGAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qgenayI3X_Sg"
      },
      "outputs": [],
      "source": [
        "cd ACCV_TinyGAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q9aUTpB1X_Sg"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wQ9TemjMX_Sg"
      },
      "outputs": [],
      "source": [
        "from model import Generator\n",
        "from utils import *\n",
        "G = Generator(image_size=128, conv_dim=32, z_dim=128, c_dim=128, repeat_num=5)\n",
        "restore_model(30, 'gan/models', G, None, None, None)\n",
        "G.to(device)\n",
        "G.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNLZ770eS4GY"
      },
      "source": [
        "Run this two cells as many times as you would like, to see different results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5EG0rKitX_Sg"
      },
      "outputs": [],
      "source": [
        "z_dim = 128\n",
        "n_row = 5\n",
        "n_samples = n_row * n_row\n",
        "noise = torch.FloatTensor(truncated_normal(n_samples*z_dim)) \\\n",
        "\t\t\t\t\t\t\t\t\t\t.view(n_samples, z_dim).to(device)\n",
        "\n",
        "label = np.random.choice(398, n_row, replace=False) # sample from all animal classes\n",
        "print(label)\n",
        "label_t = torch.tensor(label).repeat(n_row).to(device)\n",
        "\n",
        "#get the 5 predictions prediction conditioned to the label for 5 samples\n",
        "with torch.no_grad():\n",
        "  out = G(noise, label_t).detach().cpu()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AbtgyVeWX_Sg"
      },
      "outputs": [],
      "source": [
        "from torchvision.utils import save_image\n",
        "from IPython.display import Image\n",
        "save_image(denorm(out), 'demo.png', nrow=n_row)\n",
        "Image(filename='demo.png')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c81a5afb570c4284a1381ad5344acd90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f166517755ea484ca5e086a2f4cd9d66",
              "IPY_MODEL_937fbc53036c40f6be22de5651d57f27",
              "IPY_MODEL_0e2e9a5dfccc495e91bde30a60ebfc29"
            ],
            "layout": "IPY_MODEL_8ed445b9216f4e0396688b5cefafad57"
          }
        },
        "f166517755ea484ca5e086a2f4cd9d66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a7b7ff0696c464fa7ab3c70de3f5cf2",
            "placeholder": "​",
            "style": "IPY_MODEL_61bb54da25834f8689263d2eb2dac209",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "937fbc53036c40f6be22de5651d57f27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d3b5874ab3442c89581d3748a3fd519",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ba22c6239bc8414f9ec7ce6a11feabb5",
            "value": 48
          }
        },
        "0e2e9a5dfccc495e91bde30a60ebfc29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e5327ac14e348b68c471f0760364721",
            "placeholder": "​",
            "style": "IPY_MODEL_a585ed086a434fb4862503a439de621a",
            "value": " 48.0/48.0 [00:00&lt;00:00, 1.24kB/s]"
          }
        },
        "8ed445b9216f4e0396688b5cefafad57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a7b7ff0696c464fa7ab3c70de3f5cf2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61bb54da25834f8689263d2eb2dac209": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7d3b5874ab3442c89581d3748a3fd519": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba22c6239bc8414f9ec7ce6a11feabb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1e5327ac14e348b68c471f0760364721": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a585ed086a434fb4862503a439de621a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "720dd3eab2f44227a27a08d07da33ba3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1858d473b2294167b0ba7a1d356412a3",
              "IPY_MODEL_a8335150883a435ebdaff8f83747d7c8",
              "IPY_MODEL_7da9ba9584eb4c199a1ca7affcaa87a7"
            ],
            "layout": "IPY_MODEL_37455358499946e593450c4a174a960d"
          }
        },
        "1858d473b2294167b0ba7a1d356412a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f79f52d83b1843cfb0539a598855f6eb",
            "placeholder": "​",
            "style": "IPY_MODEL_b9c3662290154070804e54a31f6f9723",
            "value": "config.json: 100%"
          }
        },
        "a8335150883a435ebdaff8f83747d7c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba0c3563208b492399023b479aeba403",
            "max": 483,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bb7d925e08814c6693893ec725c1d8c6",
            "value": 483
          }
        },
        "7da9ba9584eb4c199a1ca7affcaa87a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3968ae5468a54297a99309b7b3a9697b",
            "placeholder": "​",
            "style": "IPY_MODEL_ca3cc2978efe4fffb237bda37c661acd",
            "value": " 483/483 [00:00&lt;00:00, 25.5kB/s]"
          }
        },
        "37455358499946e593450c4a174a960d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f79f52d83b1843cfb0539a598855f6eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9c3662290154070804e54a31f6f9723": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ba0c3563208b492399023b479aeba403": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb7d925e08814c6693893ec725c1d8c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3968ae5468a54297a99309b7b3a9697b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca3cc2978efe4fffb237bda37c661acd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1bf5445c79bc45abb382deb8019c059d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b8de44a84107417e95e4bbcb9bf99429",
              "IPY_MODEL_5d3db767184a4d20bd23a5254b751a8c",
              "IPY_MODEL_5b0bf6a6dac54e17bbda7ed95a0f8d2c"
            ],
            "layout": "IPY_MODEL_75eb947d793a47c3a3a8ebad3fa58c7c"
          }
        },
        "b8de44a84107417e95e4bbcb9bf99429": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cdc8f3bdc09545d9a840788a66e11837",
            "placeholder": "​",
            "style": "IPY_MODEL_0351027492f64dbbab0bff6d8a820d90",
            "value": "vocab.txt: 100%"
          }
        },
        "5d3db767184a4d20bd23a5254b751a8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62c9457f615b4a3595059116b562da5a",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5041d38bf5fe4ca3b8c336b6ba1b7fa6",
            "value": 231508
          }
        },
        "5b0bf6a6dac54e17bbda7ed95a0f8d2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5abe22d7130c4a48919cd5bece17050e",
            "placeholder": "​",
            "style": "IPY_MODEL_1af0182c7bee44b9a4799a31983fcda4",
            "value": " 232k/232k [00:00&lt;00:00, 2.32MB/s]"
          }
        },
        "75eb947d793a47c3a3a8ebad3fa58c7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cdc8f3bdc09545d9a840788a66e11837": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0351027492f64dbbab0bff6d8a820d90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "62c9457f615b4a3595059116b562da5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5041d38bf5fe4ca3b8c336b6ba1b7fa6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5abe22d7130c4a48919cd5bece17050e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1af0182c7bee44b9a4799a31983fcda4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2655ff2608bc448b826ba3a4a8d8be0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ebd4ae7240114df4acb0f6afd53fc512",
              "IPY_MODEL_371043f28b6148a097a24e4be16f222e",
              "IPY_MODEL_f5e8c674fad744c8ae0daeeebbc856bd"
            ],
            "layout": "IPY_MODEL_50668129d2fa4edaa3954fc2155b38b3"
          }
        },
        "ebd4ae7240114df4acb0f6afd53fc512": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce0a556a0f8c4ab1adb7de356872dcb6",
            "placeholder": "​",
            "style": "IPY_MODEL_981de31d3d184e7b976efaebf2ec122c",
            "value": "tokenizer.json: 100%"
          }
        },
        "371043f28b6148a097a24e4be16f222e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3ec5847eae14a50bdfb2732d3dd64c9",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f0820a0496384b1b9bdb0830bd038c4d",
            "value": 466062
          }
        },
        "f5e8c674fad744c8ae0daeeebbc856bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_61cc53055c834087b12bb3fd939793bb",
            "placeholder": "​",
            "style": "IPY_MODEL_75d216c1015a402eb79ddcc51fcfa66c",
            "value": " 466k/466k [00:00&lt;00:00, 4.56MB/s]"
          }
        },
        "50668129d2fa4edaa3954fc2155b38b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce0a556a0f8c4ab1adb7de356872dcb6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "981de31d3d184e7b976efaebf2ec122c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b3ec5847eae14a50bdfb2732d3dd64c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0820a0496384b1b9bdb0830bd038c4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "61cc53055c834087b12bb3fd939793bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75d216c1015a402eb79ddcc51fcfa66c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}